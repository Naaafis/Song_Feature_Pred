{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-zxSnMLEKDS"
      },
      "source": [
        "### Linear Combination model\n",
        "\n",
        "##### Inputs: outputs of MFCC and numerical regression models\n",
        "\n",
        "##### Output: multi-labels: Danceability, Instrumentalness, Speechiness, Acuosticness, Energy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ISsRABoPEKDW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B9565oc6EKDr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import torch\n",
        "\n",
        "import torchaudio\n",
        "import torchaudio.functional as F\n",
        "import torchaudio.transforms as T\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hhWN88a2EKDt"
      },
      "outputs": [],
      "source": [
        "labels_file = \"tracks_features.csv\"\n",
        "#labels_file = \"/content/drive/MyDrive/tracks_features.csv\"\n",
        "all_tracks = pd.read_csv(labels_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TaLl_VyYFoqZ"
      },
      "outputs": [],
      "source": [
        "loaded_mfcc_tensor = torch.load(\"C://users/khala/Downloads/mfcc_tensor (1).pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ5UWyfxEKDz"
      },
      "source": [
        "#### Import MFCC model weights locally if desired \n",
        "\n",
        "Will not work in colab, this just shows where the weights are on github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NfGCg0nYEKD1"
      },
      "outputs": [],
      "source": [
        "cnn_model_path = \"cnn_model_weights.pth\"\n",
        "rnn_model_path = \"rnn_model_weights.pth\"\n",
        "multi_task_model_path = \"multi_task_rnn_model_weights.pth\"\n",
        "linear_model_weights_path = \"linear_model_weights.pth\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cSRxgc_G33j"
      },
      "source": [
        "### 3. Multitask RNN model\n",
        "\n",
        "In first attempt to make Linear model, only this model's output should be combined with the Regression model's output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "ytCR3bJmGy5U"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiTaskRNNModel(nn.Module):\n",
        "  def __init__(self, input_size=20, hidden_size=64, num_layers=1, num_outputs=5):\n",
        "    super(MultiTaskRNNModel, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.num_outputs = num_outputs\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, num_outputs)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "    out, _ = self.lstm(x, (h0, c0))\n",
        "    #out = self.fc(out[:, -1, :])          #we remove fully connected layer and sigmoid since we are combining\n",
        "    out = out[:, -1, :]\n",
        "    #out = self.sigmoid(out)     \n",
        "\n",
        "    # Multiply by 1000, round, and then divide by 1000 for precision purposes\n",
        "    #out = torch.round(out * 1000) / 1000\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "tqD3378RHrCA"
      },
      "outputs": [],
      "source": [
        "#data_directory = \"/content/drive/MyDrive/\"\n",
        "\n",
        "model_weights_path = (\"multi_task_rnn_model_weights.pth\")\n",
        "\n",
        "# Initialize the model with the same architecture\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model = MultiTaskRNNModel()\n",
        "\n",
        "# Load the model weights\n",
        "loaded_model.load_state_dict(torch.load(model_weights_path))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "#loaded_model.eval()\n",
        "\n",
        "#initialize a loaded model\n",
        "trained_mt_rnn = loaded_model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtg84TX4IXxX"
      },
      "source": [
        "### 4. Load Numerical based regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TKA0p6zkIQW0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "I9EIimeeNQUw"
      },
      "outputs": [],
      "source": [
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.layer1 = nn.Linear(6, 64)\n",
        "        self.layer2 = nn.Linear(64, 32)\n",
        "        self.layer3 = nn.Linear(32, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.layer1(x))\n",
        "        x = torch.relu(self.layer2(x))\n",
        "        #x = self.layer3(x)\n",
        "        return x\n",
        " \n",
        "model = RegressionModel().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "pZN6CRYeT6d4"
      },
      "outputs": [],
      "source": [
        "data_directory = \"/content/drive/MyDrive/\"\n",
        "\n",
        "model_weights_path = (\"linear_model_weights.pth\")\n",
        "\n",
        "# Initialize the model with the same architecture\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model = RegressionModel()#.to(device)\n",
        "\n",
        "# Load the model weights\n",
        "loaded_model.load_state_dict(torch.load(model_weights_path))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "#loaded_model.eval()\n",
        "\n",
        "#initialize a trained linear model\n",
        "trained_lm = loaded_model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDA4ybIMNeIv"
      },
      "source": [
        "### 5. Combine linear and multitask rnn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "cOtUiCj8Ni-Z"
      },
      "outputs": [],
      "source": [
        "class CombinerModel(nn.Module):\n",
        "    def __init__(self, input_size=20, hidden_size=64, num_layers=1, num_outputs=5):\n",
        "        super(CombinerModel, self).__init__()\n",
        "        self.fc_rnn = nn.Linear(64, 32)\n",
        "        self.fc_lm = nn.Linear(32, 32)\n",
        "        self.fc_combiner = nn.Linear(64, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_rnn = x[:, 0:20*160]\n",
        "        x_lm = x[:, 20*160:20*160+6]\n",
        "        batch_size = x.shape[0]\n",
        "        x_rnn = torch.reshape(x_rnn, (batch_size, 160, 20))\n",
        "\n",
        "        out_rnn = trained_mt_rnn(x_rnn)\n",
        "        out_rnn = torch.relu(self.fc_rnn(out_rnn))\n",
        "\n",
        "        out_lm = trained_lm(x_lm)\n",
        "        out_lm = torch.relu(self.fc_lm(out_lm))\n",
        "\n",
        "        out = torch.cat((out_rnn, out_lm), 1)\n",
        "        out = self.fc_combiner(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        \n",
        "        return out\n",
        "combiner = CombinerModel().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hqUHNus2BIt",
        "outputId": "26e5d430-d623-4090-ea06-7ff79e33ad65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded MFCC tensor shape: torch.Size([21325, 1, 20, 160])\n"
          ]
        }
      ],
      "source": [
        "class CombineDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, mfcc_tensor, df):\n",
        "    self.df = df\n",
        "    self.mfcc = mfcc_tensor\n",
        "    self.mean = self.mfcc.mean()\n",
        "    self.std = self.mfcc.std()\n",
        "\n",
        "    # Standardize MFCC tensor\n",
        "    self.mfcc = (self.mfcc - self.mean) / self.std\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    labels = self.df.iloc[idx][['danceability', 'instrumentalness', 'acousticness', 'energy', 'speechiness']].astype(float).values\n",
        "    label = torch.tensor(labels, dtype=torch.float32)\n",
        "    mfcc = self.mfcc[idx]\n",
        "    x = self.df.iloc[idx][['valence', 'tempo', 'loudness', 'key', 'mode', 'time_signature']].astype(float).values\n",
        "    x = torch.tensor(x, dtype=torch.float32).cuda()\n",
        "    flatten = torch.reshape(mfcc, (-1,)).cuda()\n",
        "    vector = torch.cat((flatten, x), 0)\n",
        "    return vector, label\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load the MFCC tensor\n",
        "#myDrive = \"\"\n",
        "\n",
        "loaded_mfcc_tensor = loaded_mfcc_tensor.cuda()\n",
        "\n",
        "print(\"Loaded MFCC tensor shape:\", loaded_mfcc_tensor.shape)\n",
        "\n",
        "# Split all_tracks and the loaded MFCC tensor\n",
        "train_tracks, test_val_tracks = train_test_split(all_tracks, test_size=0.3, random_state=42)\n",
        "test_tracks, val_tracks = train_test_split(test_val_tracks, test_size=0.5, random_state=42)\n",
        "\n",
        "train_mfcc, test_val_mfcc = train_test_split(loaded_mfcc_tensor, test_size=0.3, random_state=42)\n",
        "test_mfcc, val_mfcc = train_test_split(test_val_mfcc, test_size=0.5, random_state=42)\n",
        "\n",
        "# Create the datasets\n",
        "train_dataset = CombineDataset(train_mfcc, train_tracks)\n",
        "val_dataset = CombineDataset(val_mfcc, val_tracks)\n",
        "test_dataset = CombineDataset(test_mfcc, test_tracks)\n",
        "\n",
        "# Create the data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2z4qzjn7M5u"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm # progress bar stuff\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = combiner.to(device)\n",
        "criterion = nn.SmoothL1Loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "  print(f\"working on epoch: {epoch}\")\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  for i, (inputs, labels) in enumerate(tqdm(train_loader)):\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "\n",
        "  epoch_loss = running_loss / (i + 1)\n",
        "  train_losses.append(epoch_loss)\n",
        "  print(f\"Epoch [{epoch + 1}/{num_epochs}] - Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "  model.eval()\n",
        "  val_running_loss = 0.0\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      \n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      val_running_loss += loss.item()\n",
        "\n",
        "  val_epoch_loss = val_running_loss / len(val_loader)\n",
        "  val_losses.append(val_epoch_loss)\n",
        "  print(f\"Validation Loss: {val_epoch_loss:.4f}\")\n",
        "\n",
        "# Plotting the training and validation losses\n",
        "plt.plot(train_losses, label=\"Training Loss\")\n",
        "plt.plot(val_losses, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Losses\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RJ7dpwaBKGx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "combiner.eval()\n",
        "with torch.no_grad():\n",
        "  for inputs, labels in test_loader:\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = combiner(inputs)\n",
        "\n",
        "    true_labels.extend(labels.cpu().numpy())\n",
        "    predicted_labels.extend(outputs.cpu().numpy())\n",
        "\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "for i, label in enumerate(['danceability', 'instrumentalness', 'acousticness', 'energy', 'speechiness']):\n",
        "  mse = mean_squared_error(true_labels[:, i], predicted_labels[:, i])\n",
        "  mae = mean_absolute_error(true_labels[:, i], predicted_labels[:, i])\n",
        "  rmse = np.sqrt(mse)\n",
        "  r2 = r2_score(true_labels[:, i], predicted_labels[:, i])\n",
        "  pearson_corr, p_value = pearsonr(true_labels[:, i], predicted_labels[:, i])\n",
        "\n",
        "  print(f\"Evaluation metrics for {label}:\")\n",
        "  print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "  print(f\"Mean Absolute Error: {mae:.4f}\")\n",
        "  print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
        "  print(f\"R-squared: {r2:.4f}\")\n",
        "  print(f\"Pearson's Correlation Coefficient: {pearson_corr:.4f}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model architecture tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96HHF-1qOTVW"
      },
      "source": [
        "architecture: remove final fc layer from pretrained rnn and lm model. two 32 size hidden layers and one 64 size hidden layer. \n",
        "\n",
        "```\n",
        "\n",
        "class CombinerModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CombinerModel, self).__init__()\n",
        "        self.fc_rnn = nn.Linear(64, 32)\n",
        "        self.fc_lm = nn.Linear(32, 32)\n",
        "        self.fc_combiner = nn.Linear(64, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_rnn = x[:, 0:20*160]\n",
        "        x_lm = x[:, 20*160:20*160+6]\n",
        "        batch_size = x.shape[0]\n",
        "        x_rnn = torch.reshape(x_rnn, (batch_size, 160, 20))\n",
        "\n",
        "        out_rnn = trained_mt_rnn(x_rnn)\n",
        "        out_rnn = torch.relu(self.fc_rnn(out_rnn))\n",
        "\n",
        "        out_lm = trained_lm(x_lm)\n",
        "        out_lm = torch.relu(self.fc_lm(out_lm))\n",
        "\n",
        "        out = torch.cat((out_rnn, out_lm), 1)\n",
        "        out = self.fc_combiner(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "Evaluation metrics for danceability:\n",
        "Mean Squared Error: 0.0222\n",
        "Mean Absolute Error: 0.1188\n",
        "Root Mean Squared Error: 0.1490\n",
        "R-squared: 0.2889\n",
        "Pearson's Correlation Coefficient: 0.5384\n",
        "Evaluation metrics for instrumentalness:\n",
        "Mean Squared Error: 0.0820\n",
        "Mean Absolute Error: 0.2054\n",
        "Root Mean Squared Error: 0.2863\n",
        "R-squared: 0.3280\n",
        "Pearson's Correlation Coefficient: 0.5734\n",
        "Evaluation metrics for acousticness:\n",
        "Mean Squared Error: 0.0670\n",
        "Mean Absolute Error: 0.2047\n",
        "Root Mean Squared Error: 0.2588\n",
        "R-squared: 0.4698\n",
        "Pearson's Correlation Coefficient: 0.6857\n",
        "Evaluation metrics for energy:\n",
        "Mean Squared Error: 0.0303\n",
        "Mean Absolute Error: 0.1375\n",
        "Root Mean Squared Error: 0.1739\n",
        "R-squared: 0.5842\n",
        "Pearson's Correlation Coefficient: 0.7651\n",
        "Evaluation metrics for speechiness:\n",
        "Mean Squared Error: 0.0078\n",
        "Mean Absolute Error: 0.0611\n",
        "Root Mean Squared Error: 0.0885\n",
        "R-squared: 0.0716\n",
        "Pearson's Correlation Coefficient: 0.2841\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYLI9qX2SjNd"
      },
      "source": [
        "Architecture: keep final fc layer in rnn and lm model but remove sigmoid in rnn model. two 16 size and one 32 size hidden layer.\n",
        "```\n",
        "class CombinerModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CombinerModel, self).__init__()\n",
        "        self.fc_rnn = nn.Linear(5, 16)\n",
        "        self.fc_lm = nn.Linear(5, 16)\n",
        "        self.fc_combiner = nn.Linear(32, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_rnn = x[:, 0:20*160]\n",
        "        x_lm = x[:, 20*160:20*160+6]\n",
        "        batch_size = x.shape[0]\n",
        "        x_rnn = torch.reshape(x_rnn, (batch_size, 160, 20))\n",
        "\n",
        "        out_rnn = trained_mt_rnn(x_rnn)\n",
        "        out_rnn = torch.relu(self.fc_rnn(out_rnn))\n",
        "\n",
        "        out_lm = trained_lm(x_lm)\n",
        "        out_lm = torch.relu(self.fc_lm(out_lm))\n",
        "\n",
        "        out = torch.cat((out_rnn, out_lm), 1)\n",
        "        out = self.fc_combiner(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "Evaluation metrics for danceability:\n",
        "Mean Squared Error: 0.0229\n",
        "Mean Absolute Error: 0.1201\n",
        "Root Mean Squared Error: 0.1513\n",
        "R-squared: 0.2660\n",
        "Pearson's Correlation Coefficient: 0.5196\n",
        "Evaluation metrics for instrumentalness:\n",
        "Mean Squared Error: 0.0833\n",
        "Mean Absolute Error: 0.2052\n",
        "Root Mean Squared Error: 0.2886\n",
        "R-squared: 0.3173\n",
        "Pearson's Correlation Coefficient: 0.5655\n",
        "Evaluation metrics for acousticness:\n",
        "Mean Squared Error: 0.0682\n",
        "Mean Absolute Error: 0.2059\n",
        "Root Mean Squared Error: 0.2612\n",
        "R-squared: 0.4597\n",
        "Pearson's Correlation Coefficient: 0.6795\n",
        "Evaluation metrics for energy:\n",
        "Mean Squared Error: 0.0327\n",
        "Mean Absolute Error: 0.1410\n",
        "Root Mean Squared Error: 0.1807\n",
        "R-squared: 0.5512\n",
        "Pearson's Correlation Coefficient: 0.7474\n",
        "Evaluation metrics for speechiness:\n",
        "Mean Squared Error: 0.0080\n",
        "Mean Absolute Error: 0.0641\n",
        "Root Mean Squared Error: 0.0895\n",
        "R-squared: 0.0516\n",
        "Pearson's Correlation Coefficient: 0.2591\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kHtnQlfXBrg"
      },
      "source": [
        "Architecture: keep all layers. Two size 5 and one size 10 hidden layer\n",
        "```\n",
        "class CombinerModel(nn.Module):\n",
        "    def __init__(self, input_size=20, hidden_size=64, num_layers=1, num_outputs=5):\n",
        "        super(CombinerModel, self).__init__()\n",
        "        self.fc_rnn = nn.Linear(5, 5)\n",
        "        self.fc_lm = nn.Linear(5, 5)\n",
        "        self.fc_combiner = nn.Linear(10, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_rnn = x[:, 0:20*160]\n",
        "        x_lm = x[:, 20*160:20*160+6]\n",
        "        batch_size = x.shape[0]\n",
        "        x_rnn = torch.reshape(x_rnn, (batch_size, 160, 20))\n",
        "\n",
        "        out_rnn = trained_mt_rnn(x_rnn)\n",
        "        out_rnn = torch.relu(self.fc_rnn(out_rnn))\n",
        "\n",
        "        out_lm = trained_lm(x_lm)\n",
        "        out_lm = torch.relu(self.fc_lm(out_lm))\n",
        "\n",
        "        out = torch.cat((out_rnn, out_lm), 1)\n",
        "        out = self.fc_combiner(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "Evaluation metrics for danceability:\n",
        "Mean Squared Error: 0.0236\n",
        "Mean Absolute Error: 0.1236\n",
        "Root Mean Squared Error: 0.1536\n",
        "R-squared: 0.2435\n",
        "Pearson's Correlation Coefficient: 0.4946\n",
        "Evaluation metrics for instrumentalness:\n",
        "Mean Squared Error: 0.0849\n",
        "Mean Absolute Error: 0.2097\n",
        "Root Mean Squared Error: 0.2914\n",
        "R-squared: 0.3040\n",
        "Pearson's Correlation Coefficient: 0.5519\n",
        "Evaluation metrics for acousticness:\n",
        "Mean Squared Error: 0.0716\n",
        "Mean Absolute Error: 0.2105\n",
        "Root Mean Squared Error: 0.2676\n",
        "R-squared: 0.4329\n",
        "Pearson's Correlation Coefficient: 0.6591\n",
        "Evaluation metrics for energy:\n",
        "Mean Squared Error: 0.0338\n",
        "Mean Absolute Error: 0.1445\n",
        "Root Mean Squared Error: 0.1839\n",
        "R-squared: 0.5351\n",
        "Pearson's Correlation Coefficient: 0.7319\n",
        "Evaluation metrics for speechiness:\n",
        "Mean Squared Error: 0.0083\n",
        "Mean Absolute Error: 0.0603\n",
        "Root Mean Squared Error: 0.0911\n",
        "R-squared: 0.0167\n",
        "Pearson's Correlation Coefficient: 0.1563\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NR7Unuda1OS"
      },
      "source": [
        "changing learning rate: 0.01, 0.005, 0.002, 0.001\n",
        "architecture: remove final fc layer in rnn and lm model\n",
        "\n",
        "```\n",
        "class CombinerModel(nn.Module):\n",
        "    def __init__(self, input_size=20, hidden_size=64, num_layers=1, num_outputs=5):\n",
        "        super(CombinerModel, self).__init__()\n",
        "        self.fc_rnn = nn.Linear(64, 32)\n",
        "        self.fc_lm = nn.Linear(32, 32)\n",
        "        self.fc_combiner = nn.Linear(64, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_rnn = x[:, 0:20*160]\n",
        "        x_lm = x[:, 20*160:20*160+6]\n",
        "        batch_size = x.shape[0]\n",
        "        x_rnn = torch.reshape(x_rnn, (batch_size, 160, 20))\n",
        "\n",
        "        out_rnn = trained_mt_rnn(x_rnn)\n",
        "        out_rnn = torch.relu(self.fc_rnn(out_rnn))\n",
        "\n",
        "        out_lm = trained_lm(x_lm)\n",
        "        out_lm = torch.relu(self.fc_lm(out_lm))\n",
        "\n",
        "        out = torch.cat((out_rnn, out_lm), 1)\n",
        "        out = self.fc_combiner(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "Evaluation metrics for danceability:\n",
        "Mean Squared Error: 0.0218\n",
        "Mean Absolute Error: 0.1172\n",
        "Root Mean Squared Error: 0.1477\n",
        "R-squared: 0.3004\n",
        "Pearson's Correlation Coefficient: 0.5485\n",
        "Evaluation metrics for instrumentalness:\n",
        "Mean Squared Error: 0.0821\n",
        "Mean Absolute Error: 0.2002\n",
        "Root Mean Squared Error: 0.2865\n",
        "R-squared: 0.3269\n",
        "Pearson's Correlation Coefficient: 0.5739\n",
        "Evaluation metrics for acousticness:\n",
        "Mean Squared Error: 0.0658\n",
        "Mean Absolute Error: 0.1963\n",
        "Root Mean Squared Error: 0.2565\n",
        "R-squared: 0.4791\n",
        "Pearson's Correlation Coefficient: 0.6941\n",
        "Evaluation metrics for energy:\n",
        "Mean Squared Error: 0.0297\n",
        "Mean Absolute Error: 0.1347\n",
        "Root Mean Squared Error: 0.1725\n",
        "R-squared: 0.5912\n",
        "Pearson's Correlation Coefficient: 0.7705\n",
        "Evaluation metrics for speechiness:\n",
        "Mean Squared Error: 0.0076\n",
        "Mean Absolute Error: 0.0583\n",
        "Root Mean Squared Error: 0.0874\n",
        "R-squared: 0.0962\n",
        "Pearson's Correlation Coefficient: 0.3114\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "audio_dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
