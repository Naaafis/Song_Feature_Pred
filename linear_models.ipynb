{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-zxSnMLEKDS"
      },
      "source": [
        "### Linear Combination model\n",
        "\n",
        "##### Inputs: outputs of MFCC and numerical regression models\n",
        "\n",
        "##### Output: multi-labels: Danceability, Instrumentalness, Speechiness, Acuosticness, Energy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ISsRABoPEKDW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B9565oc6EKDr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import torch\n",
        "\n",
        "import torchaudio\n",
        "import torchaudio.functional as F\n",
        "import torchaudio.transforms as T\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfWg8yFEEKDu"
      },
      "source": [
        "#### ONLY RUN IN GOOGLE COLAB ###"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSi4Tj37Elpc",
        "outputId": "ed58feeb-f854-46d7-a975-2eb4dadaf302"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hhWN88a2EKDt"
      },
      "outputs": [],
      "source": [
        "# labels_file = \"Data/tracks_features.csv\"\n",
        "labels_file = \"/content/drive/MyDrive/tracks_features.csv\"\n",
        "all_tracks = pd.read_csv(labels_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CxO4qbgoEKDv"
      },
      "outputs": [],
      "source": [
        "def name_of_file(track_id):\n",
        "  filename = f\"/content/drive/MyDrive/tracks_features_audio/{track_id}_audio.mp3\"\n",
        "  return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBAJKU4bEKDw",
        "outputId": "c17dd7aa-3bfb-4560-d266-03e1961418dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded MFCC tensor shape: torch.Size([21325, 1, 20, 160])\n"
          ]
        }
      ],
      "source": [
        "myDrive = \"/content/drive/MyDrive/\"\n",
        "tensor_file = os.path.join(os.path.dirname(myDrive), \"mfcc_tensor.pt\")\n",
        "\n",
        "# Load the tensor back and print the shape\n",
        "loaded_mfcc_tensor = torch.load(tensor_file)\n",
        "print(\"Loaded MFCC tensor shape:\", loaded_mfcc_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ5UWyfxEKDz"
      },
      "source": [
        "#### Import MFCC model weights locally if desired \n",
        "\n",
        "Will not work in colab, this just shows where the weights are on github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfGCg0nYEKD1"
      },
      "outputs": [],
      "source": [
        "cnn_model_path = \"models/cnn_model_weights.pth\"\n",
        "rnn_model_path = \"models/rnn_model_weights.pth\"\n",
        "multi_task_model_path = \"models/multi_task_rnn_model_weights.pth\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Load CNN MFCC Model\n",
        "\n",
        "It should be noted that this model only predicts danceability. If the following weights are taken as is, we should only see an improvement in performance for danceability. \n",
        "\n",
        "*** Note that this model may not function in the Linear model since it is not a multitask model ***"
      ],
      "metadata": {
        "id": "4Vv3dZe4Fssm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset loader for 2D CNN model (Only danceability labels)"
      ],
      "metadata": {
        "id": "VPT-ge_FFCD8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8EVqgLplEKD1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class AudioDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, mfcc_tensor, df):\n",
        "    self.df = df\n",
        "    self.mfcc = mfcc_tensor\n",
        "    self.mean = self.mfcc.mean()\n",
        "    self.std = self.mfcc.std()\n",
        "\n",
        "    # Standardize MFCC tensor\n",
        "    self.mfcc = (self.mfcc - self.mean) / self.std\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    label = torch.tensor(self.df.iloc[idx]['danceability'], dtype=torch.float32)\n",
        "    mfcc = self.mfcc[idx]\n",
        "    return mfcc, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t5xBnUaEKD5",
        "outputId": "fd34e4dc-bbc8-4093-b761-c49fc8e23293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded MFCC tensor shape: torch.Size([21325, 20, 160])\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load the MFCC tensor\n",
        "myDrive = \"/content/drive/MyDrive/\"\n",
        "tensor_file = os.path.join(os.path.dirname(myDrive), \"mfcc_tensor.pt\")\n",
        "loaded_mfcc_tensor = torch.load(tensor_file).squeeze(1)\n",
        "print(\"Loaded MFCC tensor shape:\", loaded_mfcc_tensor.shape)\n",
        "\n",
        "# Split all_tracks and the loaded MFCC tensor\n",
        "train_tracks, test_val_tracks = train_test_split(all_tracks, test_size=0.3, random_state=42)\n",
        "test_tracks, val_tracks = train_test_split(test_val_tracks, test_size=0.5, random_state=42)\n",
        "\n",
        "train_mfcc, test_val_mfcc = train_test_split(loaded_mfcc_tensor, test_size=0.3, random_state=42)\n",
        "test_mfcc, val_mfcc = train_test_split(test_val_mfcc, test_size=0.5, random_state=42)\n",
        "\n",
        "# Create the datasets\n",
        "train_dataset = AudioDataset(train_mfcc, train_tracks)\n",
        "val_dataset = AudioDataset(val_mfcc, val_tracks)\n",
        "test_dataset = AudioDataset(test_mfcc, test_tracks)\n",
        "\n",
        "# Create the data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# 2D CNN Model\n",
        "class CNNModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNNModel, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "    self.fc1 = nn.Linear(32 * 5 * 40, 64)\n",
        "    self.fc2 = nn.Linear(64, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = nn.functional.relu(self.conv1(x))\n",
        "    x = nn.functional.max_pool2d(x, 2)\n",
        "    x = nn.functional.relu(self.conv2(x))\n",
        "    x = nn.functional.max_pool2d(x, 2)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = nn.functional.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    x = self.sigmoid(x)\n",
        "    \n",
        "    # Multiply by 1000, round, and then divide by 1000 for precision purposes\n",
        "    # x = torch.round(x * 1000) / 1000 # prevents loss from doing down\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "beg4LBsCFGH2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = \"/content/drive/MyDrive/\"\n",
        "\n",
        "# loading for colab, choose based on where you place your model paths\n",
        "model_weights_path = os.path.join(data_directory, \"cnn_model_weights.pth\")"
      ],
      "metadata": {
        "id": "awg8v1feFJeE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model weights\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model = CNNModel().to(device)\n",
        "loaded_model.load_state_dict(torch.load(model_weights_path))\n",
        "loaded_model.eval()  # Set the model to evaluation mode\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpUtKKUpFVLo",
        "outputId": "874f0203-b25f-446e-86d7-2a49574360c4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=6400, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "loaded_model.eval()\n",
        "with torch.no_grad():\n",
        "  for inputs, labels in test_loader:\n",
        "    inputs = inputs.unsqueeze(1).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = loaded_model(inputs)\n",
        "\n",
        "    true_labels.extend(labels.cpu().numpy())\n",
        "    predicted_labels.extend(outputs.squeeze().cpu().numpy())\n",
        "\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "mse = mean_squared_error(true_labels, predicted_labels)\n",
        "mae = mean_absolute_error(true_labels, predicted_labels)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(true_labels, predicted_labels)\n",
        "pearson_corr, p_value = pearsonr(true_labels, predicted_labels)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
        "print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
        "print(f\"R-squared: {r2:.4f}\")\n",
        "print(f\"Pearson's Correlation Coefficient: {pearson_corr:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt1u3O_YFcU1",
        "outputId": "e1163ea1-9abb-442b-a80c-4121947287a1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.0110\n",
            "Mean Absolute Error: 0.0800\n",
            "Root Mean Squared Error: 0.1048\n",
            "R-squared: 0.6481\n",
            "Pearson's Correlation Coefficient: 0.8114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Load 1D RNN MFCC model (Also Danceability only)"
      ],
      "metadata": {
        "id": "yqO4YxtrFz1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1D RNN Model\n",
        "import torch.nn as nn\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "  def __init__(self, input_size=20, hidden_size=64, num_layers=1):\n",
        "    super(RNNModel, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "    out, _ = self.lstm(x, (h0, c0))\n",
        "    out = self.fc(out[:, -1, :])\n",
        "    return out"
      ],
      "metadata": {
        "id": "dMPzzVkPFfAt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = \"/content/drive/MyDrive/\"\n",
        "rnn_model_weights_path = os.path.join(data_directory, \"rnn_model_weights.pth\")\n",
        "\n",
        "# Create a new instance of the RNN model\n",
        "loaded_model = RNNModel()\n",
        "\n",
        "# Load the model weights from the saved state dictionary\n",
        "loaded_model.load_state_dict(torch.load(model_weights_path))\n",
        "\n",
        "# Move the model to the device (if you used GPU while training)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "loaded_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emJk38iGF3vz",
        "outputId": "b418bbbb-b717-4cba-a73a-a7072e4e4830"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNModel(\n",
              "  (lstm): LSTM(20, 64, batch_first=True)\n",
              "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sample of using the model"
      ],
      "metadata": {
        "id": "ffjvS6eKIHWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Choose the index of the sample you want to examine\n",
        "sample_index = 1010\n",
        "\n",
        "# Load the saved MFCC tensor\n",
        "myDrive = \"/content/drive/MyDrive/\"\n",
        "tensor_file = os.path.join(os.path.dirname(myDrive), \"mfcc_tensor.pt\")\n",
        "loaded_mfcc_tensor = torch.load(tensor_file).squeeze(1)\n",
        "\n",
        "# Extract the input features (MFCCs) and the true label for the sample\n",
        "sample_mfcc = loaded_mfcc_tensor[sample_index].unsqueeze(0)\n",
        "true_label = all_tracks.iloc[sample_index][\"danceability\"]\n",
        "\n",
        "# Pass the input features through the trained RNN model to get the outputted label\n",
        "loaded_model.eval()\n",
        "with torch.no_grad():\n",
        "  sample_input = sample_mfcc.permute(0, 2, 1).to(device)\n",
        "  output_label = loaded_model(sample_input).item()\n",
        "\n",
        "# Print both the true label and the outputted label\n",
        "print(f\"True label: {true_label}\")\n",
        "print(f\"Outputted label: {output_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqdr6BkXF_oW",
        "outputId": "b003d42c-e1e0-4ce9-9224-a61258e6c4fe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True label: 0.247\n",
            "Outputted label: 0.023576393723487854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "loaded_model.eval()\n",
        "all_outputs = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for inputs, labels in test_loader:\n",
        "    inputs = inputs.permute(0, 2, 1)\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    outputs = loaded_model(inputs)\n",
        "    all_outputs.extend(outputs.squeeze().tolist())\n",
        "    all_labels.extend(labels.tolist())\n",
        "\n",
        "mse = mean_squared_error(all_labels, all_outputs)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(all_labels, all_outputs)\n",
        "r2 = r2_score(all_labels, all_outputs)\n",
        "pearson_corr, p_value = pearsonr(all_labels, all_outputs)\n",
        "\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"R-squared: {r2:.4f}\")\n",
        "print(f\"Pearson's Correlation Coefficient: {pearson_corr:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_dIxQ8RGtpc",
        "outputId": "753ed5f4-5b10-42f0-9147-2143cfb321c2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.0104\n",
            "RMSE: 0.1018\n",
            "MAE: 0.0786\n",
            "R-squared: 0.6682\n",
            "Pearson's Correlation Coefficient: 0.8297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Multitask RNN model\n",
        "\n",
        "In first attempt to make Linear model, only this model's output should be combined with the Regression model's output"
      ],
      "metadata": {
        "id": "7cSRxgc_G33j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiTaskRNNModel(nn.Module):\n",
        "  def __init__(self, input_size=20, hidden_size=64, num_layers=1, num_outputs=5):\n",
        "    super(MultiTaskRNNModel, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.num_outputs = num_outputs\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, num_outputs)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "    out, _ = self.lstm(x, (h0, c0))\n",
        "    out = self.fc(out[:, -1, :])\n",
        "    out = self.sigmoid(out)\n",
        "\n",
        "    # Multiply by 1000, round, and then divide by 1000 for precision purposes\n",
        "    #out = torch.round(out * 1000) / 1000\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "ytCR3bJmGy5U"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, mfcc_tensor, df):\n",
        "    self.df = df\n",
        "    self.mfcc = mfcc_tensor\n",
        "    self.mean = self.mfcc.mean()\n",
        "    self.std = self.mfcc.std()\n",
        "\n",
        "    # Standardize MFCC tensor\n",
        "    self.mfcc = (self.mfcc - self.mean) / self.std\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    labels = self.df.iloc[idx][['danceability', 'instrumentalness', 'acousticness', 'energy', 'speechiness']].astype(float).values\n",
        "    label = torch.tensor(labels, dtype=torch.float32)\n",
        "    mfcc = self.mfcc[idx]\n",
        "    return mfcc, label\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load the MFCC tensor\n",
        "myDrive = \"/content/drive/MyDrive/\"\n",
        "tensor_file = os.path.join(os.path.dirname(myDrive), \"mfcc_tensor.pt\")\n",
        "loaded_mfcc_tensor = torch.load(tensor_file).squeeze(1)\n",
        "print(\"Loaded MFCC tensor shape:\", loaded_mfcc_tensor.shape)\n",
        "\n",
        "# Split all_tracks and the loaded MFCC tensor\n",
        "train_tracks, test_val_tracks = train_test_split(all_tracks, test_size=0.3, random_state=42)\n",
        "test_tracks, val_tracks = train_test_split(test_val_tracks, test_size=0.5, random_state=42)\n",
        "\n",
        "train_mfcc, test_val_mfcc = train_test_split(loaded_mfcc_tensor, test_size=0.3, random_state=42)\n",
        "test_mfcc, val_mfcc = train_test_split(test_val_mfcc, test_size=0.5, random_state=42)\n",
        "\n",
        "# Create the datasets\n",
        "train_dataset = AudioDataset(train_mfcc, train_tracks)\n",
        "val_dataset = AudioDataset(val_mfcc, val_tracks)\n",
        "test_dataset = AudioDataset(test_mfcc, test_tracks)\n",
        "\n",
        "# Create the data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8moBSxsHocq",
        "outputId": "eaf91779-d347-47fa-a486-70106185821f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded MFCC tensor shape: torch.Size([21325, 20, 160])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = \"/content/drive/MyDrive/\"\n",
        "\n",
        "model_weights_path = os.path.join(data_directory, \"multi_task_rnn_model_weights.pth\")\n",
        "\n",
        "# Initialize the model with the same architecture\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model = MultiTaskRNNModel().to(device)\n",
        "\n",
        "# Load the model weights\n",
        "loaded_model.load_state_dict(torch.load(model_weights_path))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "loaded_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqD3378RHrCA",
        "outputId": "6c264706-bf3f-4c92-8cca-ef0512042c32"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiTaskRNNModel(\n",
              "  (lstm): LSTM(20, 64, batch_first=True)\n",
              "  (fc): Linear(in_features=64, out_features=5, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sample of using the model for predictions"
      ],
      "metadata": {
        "id": "RHzXzClwH9qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Choose the index of the sample you want to examine\n",
        "sample_index = 1013\n",
        "\n",
        "# Load the saved MFCC tensor\n",
        "myDrive = \"/content/drive/MyDrive/\"\n",
        "tensor_file = os.path.join(os.path.dirname(myDrive), \"mfcc_tensor.pt\")\n",
        "loaded_mfcc_tensor = torch.load(tensor_file).squeeze(1)\n",
        "\n",
        "# Extract the input features (MFCCs) and the true labels for the sample\n",
        "sample_mfcc = loaded_mfcc_tensor[sample_index].unsqueeze(0)\n",
        "true_labels = all_tracks.iloc[sample_index][['danceability', 'instrumentalness', 'acousticness', 'energy', 'speechiness']].values\n",
        "\n",
        "# Pass the input features through the trained RNN model to get the outputted labels\n",
        "loaded_model.eval()\n",
        "with torch.no_grad():\n",
        "  sample_input = sample_mfcc.permute(0, 2, 1).to(device)\n",
        "  output_labels = loaded_model(sample_input).cpu().numpy()[0]\n",
        "\n",
        "# Print both the true labels and the outputted labels\n",
        "labels = ['danceability', 'instrumentalness', 'acousticness', 'energy', 'speechiness']\n",
        "for i, label in enumerate(labels):\n",
        "  print(f\"{label} - True label: {true_labels[i]:.3f}, Outputted label: {output_labels[i]:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JikId79qH4kp",
        "outputId": "632208de-3569-40f4-9f92-1439194a60cc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "danceability - True label: 0.331, Outputted label: 0.691\n",
            "instrumentalness - True label: 0.000, Outputted label: 0.005\n",
            "acousticness - True label: 0.006, Outputted label: 0.072\n",
            "energy - True label: 0.471, Outputted label: 0.858\n",
            "speechiness - True label: 0.030, Outputted label: 0.155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model statistics"
      ],
      "metadata": {
        "id": "ZBZKkuYSIRsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "loaded_model.eval()\n",
        "with torch.no_grad():\n",
        "  for inputs, labels in test_loader:\n",
        "    inputs = inputs.permute(0, 2, 1).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = loaded_model(inputs)\n",
        "\n",
        "    true_labels.extend(labels.cpu().numpy())\n",
        "    predicted_labels.extend(outputs.cpu().numpy())\n",
        "\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "for i, label in enumerate(['danceability', 'instrumentalness', 'acousticness', 'energy', 'speechiness']):\n",
        "  mse = mean_squared_error(true_labels[:, i], predicted_labels[:, i])\n",
        "  mae = mean_absolute_error(true_labels[:, i], predicted_labels[:, i])\n",
        "  rmse = np.sqrt(mse)\n",
        "  r2 = r2_score(true_labels[:, i], predicted_labels[:, i])\n",
        "  pearson_corr, p_value = pearsonr(true_labels[:, i], predicted_labels[:, i])\n",
        "\n",
        "  print(f\"Evaluation metrics for {label}:\")\n",
        "  print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "  print(f\"Mean Absolute Error: {mae:.4f}\")\n",
        "  print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
        "  print(f\"R-squared: {r2:.4f}\")\n",
        "  print(f\"Pearson's Correlation Coefficient: {pearson_corr:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvcnL_0dH8Sa",
        "outputId": "55a95949-f943-48b5-ef9b-588debe9af27"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metrics for danceability:\n",
            "Mean Squared Error: 0.0194\n",
            "Mean Absolute Error: 0.1109\n",
            "Root Mean Squared Error: 0.1393\n",
            "R-squared: 0.3783\n",
            "Pearson's Correlation Coefficient: 0.6151\n",
            "Evaluation metrics for instrumentalness:\n",
            "Mean Squared Error: 0.0520\n",
            "Mean Absolute Error: 0.1408\n",
            "Root Mean Squared Error: 0.2281\n",
            "R-squared: 0.5734\n",
            "Pearson's Correlation Coefficient: 0.7719\n",
            "Evaluation metrics for acousticness:\n",
            "Mean Squared Error: 0.0241\n",
            "Mean Absolute Error: 0.1134\n",
            "Root Mean Squared Error: 0.1552\n",
            "R-squared: 0.8093\n",
            "Pearson's Correlation Coefficient: 0.9014\n",
            "Evaluation metrics for energy:\n",
            "Mean Squared Error: 0.0179\n",
            "Mean Absolute Error: 0.1068\n",
            "Root Mean Squared Error: 0.1337\n",
            "R-squared: 0.7543\n",
            "Pearson's Correlation Coefficient: 0.8759\n",
            "Evaluation metrics for speechiness:\n",
            "Mean Squared Error: 0.0074\n",
            "Mean Absolute Error: 0.0541\n",
            "Root Mean Squared Error: 0.0862\n",
            "R-squared: 0.1204\n",
            "Pearson's Correlation Coefficient: 0.3632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Load Numerical based regression model"
      ],
      "metadata": {
        "id": "qtg84TX4IXxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "TKA0p6zkIQW0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = all_tracks"
      ],
      "metadata": {
        "id": "lREKOgukNDXn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['valence', 'tempo', 'loudness', 'key', 'mode', 'time_signature']]\n",
        "y = df[['danceability', 'energy', 'speechiness', 'acousticness', 'instrumentalness']]"
      ],
      "metadata": {
        "id": "I9EIimeeNQUw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "-rxE4kzwNkwf"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "T9VYmetbNljM"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=6, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(5, activation='linear'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "metadata": {
        "id": "os9ggqwdNrsU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3F4-xzP5NudY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "audio_dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}