{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation and importing client ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spotipy\n",
      "  Using cached spotipy-2.22.1-py3-none-any.whl (28 kB)\n",
      "Collecting redis>=3.5.3\n",
      "  Downloading redis-4.5.4-py3-none-any.whl (238 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.25.0 in /Users/cheffbcookin/opt/anaconda3/envs/song_pred/lib/python3.11/site-packages (from spotipy) (2.28.2)\n",
      "Requirement already satisfied: six>=1.15.0 in /Users/cheffbcookin/opt/anaconda3/envs/song_pred/lib/python3.11/site-packages (from spotipy) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/cheffbcookin/opt/anaconda3/envs/song_pred/lib/python3.11/site-packages (from spotipy) (1.26.15)\n",
      "Collecting async-timeout>=4.0.2\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cheffbcookin/opt/anaconda3/envs/song_pred/lib/python3.11/site-packages (from requests>=2.25.0->spotipy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cheffbcookin/opt/anaconda3/envs/song_pred/lib/python3.11/site-packages (from requests>=2.25.0->spotipy) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cheffbcookin/opt/anaconda3/envs/song_pred/lib/python3.11/site-packages (from requests>=2.25.0->spotipy) (2022.12.7)\n",
      "Installing collected packages: async-timeout, redis, spotipy\n",
      "Successfully installed async-timeout-4.0.2 redis-4.5.4 spotipy-2.22.1\n"
     ]
    }
   ],
   "source": [
    "!pip install spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.0.0-cp311-none-macosx_10_9_x86_64.whl (139.5 MB)\n",
      "Requirement already satisfied: filelock in /Users/cheffbcookin/opt/anaconda3/envs/song_pred/lib/python3.11/site-packages (from torch) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions in /Users/cheffbcookin/opt/anaconda3/envs/song_pred/lib/python3.11/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /Users/cheffbcookin/opt/anaconda3/envs/song_pred/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/cheffbcookin/opt/anaconda3/envs/song_pred/lib/python3.11/site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /Users/cheffbcookin/opt/anaconda3/envs/song_pred/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/cheffbcookin/opt/anaconda3/envs/song_pred/lib/python3.11/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/cheffbcookin/opt/anaconda3/envs/song_pred/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import torch\n",
    "#import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "cid = '49789426e6c04428a2befbd3c2d79b02'\n",
    "secret = 'd18032252a0d4634aa8ca21356894e79'\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the existing csv files as dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "danceable_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/danceable_tracks-1.csv')\n",
    "non_danceable_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/non-danceable_tracks-1.csv')\n",
    "instrumental_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/instrumental_tracks-1.csv')\n",
    "non_instrumental_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/non-instrumental_tracks-1.csv')\n",
    "speechy_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/speechy_tracks-1.csv')\n",
    "non_speechy_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/non-speechy_tracks-1.csv')\n",
    "acoustic_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/acoustic_tracks-1.csv')\n",
    "non_acoustic_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/non-acoustic_tracks-1.csv')\n",
    "energetic_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/energetic_tracks-1.csv')\n",
    "non_energetic_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/non-energetic_tracks-1.csv')\n",
    "all_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/all_tracks-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'Danceable Tracks': danceable_tracks_df,\n",
    "    'Non-danceable Tracks': non_danceable_tracks_df,\n",
    "    'Instrumental Tracks': instrumental_tracks_df,\n",
    "    'Non-instrumental Tracks': non_instrumental_tracks_df,\n",
    "    'Speechy Tracks': speechy_tracks_df,\n",
    "    'Non-speechy Tracks': non_speechy_tracks_df,\n",
    "    'Acoustic Tracks': acoustic_tracks_df,\n",
    "    'Non-acoustic Tracks': non_acoustic_tracks_df,\n",
    "    'Energetic Tracks': energetic_tracks_df,\n",
    "    'Non-energetic Tracks': non_energetic_tracks_df,\n",
    "    'All Tracks': all_tracks_df\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize dictionary to hold list of tracks with specific features\n",
    "\n",
    "We will later save this dictionary and reuse it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing DataFrame from CSV file (if it exists)\n",
    "try:\n",
    "    tracks_data = pd.read_csv('tracks_data.csv')\n",
    "except FileNotFoundError:\n",
    "    tracks_data = pd.DataFrame(columns=['track_id', 'track_name', 'track_artist', 'preview_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gd/pxcx2w0x59j2bsjbzhy62nvw0000gn/T/ipykernel_5173/1520926489.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
      "/var/folders/gd/pxcx2w0x59j2bsjbzhy62nvw0000gn/T/ipykernel_5173/1520926489.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
      "/var/folders/gd/pxcx2w0x59j2bsjbzhy62nvw0000gn/T/ipykernel_5173/1520926489.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
      "/var/folders/gd/pxcx2w0x59j2bsjbzhy62nvw0000gn/T/ipykernel_5173/1520926489.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
      "/var/folders/gd/pxcx2w0x59j2bsjbzhy62nvw0000gn/T/ipykernel_5173/1520926489.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
      "/var/folders/gd/pxcx2w0x59j2bsjbzhy62nvw0000gn/T/ipykernel_5173/1520926489.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
      "/var/folders/gd/pxcx2w0x59j2bsjbzhy62nvw0000gn/T/ipykernel_5173/1520926489.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
      "/var/folders/gd/pxcx2w0x59j2bsjbzhy62nvw0000gn/T/ipykernel_5173/1520926489.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
      "/var/folders/gd/pxcx2w0x59j2bsjbzhy62nvw0000gn/T/ipykernel_5173/1520926489.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
      "/var/folders/gd/pxcx2w0x59j2bsjbzhy62nvw0000gn/T/ipykernel_5173/1520926489.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
      "/var/folders/gd/pxcx2w0x59j2bsjbzhy62nvw0000gn/T/ipykernel_5173/1520926489.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
      "/var/folders/gd/pxcx2w0x59j2bsjbzhy62nvw0000gn/T/ipykernel_5173/1520926489.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 379 tracks\n",
      "                 track_id          track_name  track_artist  \\\n",
      "0  4JRIH7oRNb2OyK5FtW6LrU           Breakable       Dabaill   \n",
      "1  7c6CyAPPp4Lq9vJ00LTi5R          Dance Baby  Michael Ward   \n",
      "2  5ssQlsPUmOqvN8788Mjddu  Dance Lovers - 4/4     Ballerina   \n",
      "3  405GG3OKeb6xsFQsXpJIL2          Dance Life      Puteroxy   \n",
      "4  3nAstOmd0ZxExayGe6QxN1     She's Dangerous  Tom Tom Club   \n",
      "\n",
      "                                         preview_url  \n",
      "0  https://p.scdn.co/mp3-preview/93cf917c0fda88db...  \n",
      "1  https://p.scdn.co/mp3-preview/6b2082270aef17b3...  \n",
      "2  https://p.scdn.co/mp3-preview/99883ba697f0e723...  \n",
      "3  https://p.scdn.co/mp3-preview/cc0f48017b69c1be...  \n",
      "4  https://p.scdn.co/mp3-preview/1f64f384fbe53208...  \n"
     ]
    }
   ],
   "source": [
    "# Define danceability range and step size\n",
    "start_danceability = 0.7\n",
    "end_danceability = 1.0\n",
    "step_size = 0.001\n",
    "\n",
    "# Iterate over danceability values and perform searches\n",
    "for danceability in reversed(range(int(start_danceability / step_size), int(end_danceability / step_size))):\n",
    "    # Define search query\n",
    "    query = f'danceability:{danceability*step_size:.2f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "            track_name = track['name']\n",
    "            track_artist = track['artists'][0]['name']\n",
    "            preview_url = track['preview_url']\n",
    "            tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "\n",
    "# Print number of tracks found and write to CSV file\n",
    "print(f'Found {len(tracks_data)} tracks')\n",
    "\n",
    "# Print tracks_data DataFrame\n",
    "print(tracks_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1399 tracks\n"
     ]
    }
   ],
   "source": [
    "# We will save the data to a CSV file so that we can use it later\n",
    "\n",
    "tracks_data.to_csv('tracks_data.csv', index=False)\n",
    "print(f'Found {len(tracks_data)} tracks')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We did it for danceability as test feature. Now we do it for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15371 tracks\n"
     ]
    }
   ],
   "source": [
    "# load the data from the CSV file\n",
    "tracks_data = pd.read_csv('tracks_data_plus.csv')\n",
    "print(f'Found {len(tracks_data)} tracks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature range and step size\n",
    "start = 0.0\n",
    "end = 1.0\n",
    "step_size = 0.005\n",
    "\n",
    "# Iterate over danceability values and perform searches\n",
    "for feature in reversed(range(int(start / step_size), int(end / step_size))):\n",
    "    # Define search query\n",
    "    print(f'working with feature interval: {feature*step_size:.3f}')\n",
    "    query = f'danceability:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id']:\n",
    "            if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "                track_name = track['name']\n",
    "                track_artist = track['artists'][0]['name']\n",
    "                preview_url = track['preview_url']\n",
    "                tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "\n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data.csv', index=False)\n",
    "    \n",
    "    # Define search query\n",
    "    query = f'instrumentalness:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id']:\n",
    "            track_id = track['id']\n",
    "            if track_id not in tracks_data['track_id'].values:\n",
    "                track_name = track['name']\n",
    "                track_artist = track['artists'][0]['name']\n",
    "                preview_url = track['preview_url']\n",
    "                tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "\n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data.csv', index=False)\n",
    "    \n",
    "    # Define search query\n",
    "    query = f'speechiness:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id']:\n",
    "            if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "                track_name = track['name']\n",
    "                track_artist = track['artists'][0]['name']\n",
    "                preview_url = track['preview_url']\n",
    "                tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "\n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data.csv', index=False)\n",
    "    \n",
    "    # Define search query\n",
    "    query = f'acousticness:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id']:\n",
    "            if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "                track_name = track['name']\n",
    "                track_artist = track['artists'][0]['name']\n",
    "                preview_url = track['preview_url']\n",
    "                tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "\n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data.csv', index=False)\n",
    "    \n",
    "    # Define search query\n",
    "    query = f'energy:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id']:\n",
    "            if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "                track_name = track['name']\n",
    "                track_artist = track['artists'][0]['name']\n",
    "                preview_url = track['preview_url']\n",
    "                tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "\n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THIS IS ONLY IF WE NEED EVEN MORE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with feature interval: 0.999\n",
      "Found 15371 tracks\n",
      "Found 15371 tracks\n",
      "Found 15372 tracks\n",
      "Found 15372 tracks\n",
      "Found 15373 tracks\n",
      "working with feature interval: 0.998\n",
      "Found 15382 tracks\n",
      "Found 15382 tracks\n",
      "Found 15384 tracks\n",
      "Found 15384 tracks\n",
      "Found 15384 tracks\n",
      "working with feature interval: 0.997\n",
      "Found 15385 tracks\n",
      "Found 15385 tracks\n",
      "Found 15386 tracks\n",
      "Found 15386 tracks\n",
      "Found 15386 tracks\n",
      "working with feature interval: 0.996\n",
      "Found 15386 tracks\n",
      "Found 15386 tracks\n",
      "Found 15387 tracks\n",
      "Found 15387 tracks\n",
      "Found 15387 tracks\n",
      "working with feature interval: 0.995\n",
      "Found 15393 tracks\n",
      "Found 15393 tracks\n",
      "Found 15394 tracks\n",
      "Found 15399 tracks\n",
      "Found 15405 tracks\n",
      "working with feature interval: 0.994\n",
      "Found 15405 tracks\n",
      "Found 15405 tracks\n",
      "Found 15406 tracks\n",
      "Found 15406 tracks\n",
      "Found 15406 tracks\n",
      "working with feature interval: 0.993\n",
      "Found 15411 tracks\n",
      "Found 15411 tracks\n",
      "Found 15412 tracks\n",
      "Found 15412 tracks\n",
      "Found 15412 tracks\n",
      "working with feature interval: 0.992\n",
      "Found 15415 tracks\n",
      "Found 15415 tracks\n",
      "Found 15416 tracks\n",
      "Found 15427 tracks\n",
      "Found 15438 tracks\n",
      "working with feature interval: 0.991\n",
      "Found 15446 tracks\n",
      "Found 15446 tracks\n",
      "Found 15448 tracks\n",
      "Found 15450 tracks\n",
      "Found 15458 tracks\n",
      "working with feature interval: 0.990\n"
     ]
    }
   ],
   "source": [
    "# Define feature range and step size\n",
    "start = 0.0\n",
    "end = 1.0\n",
    "step_size = 0.001\n",
    "\n",
    "# Iterate over danceability values and perform searches\n",
    "for feature in reversed(range(int(start / step_size), int(end / step_size))):\n",
    "    # Define search query\n",
    "    print(f'working with feature interval: {feature*step_size:.3f}')\n",
    "    query = f'danceability:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "            track_name = track['name']\n",
    "            track_artist = track['artists'][0]['name']\n",
    "            preview_url = track['preview_url']\n",
    "            df_temp = pd.DataFrame({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, index=[0])\n",
    "            #tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "            tracks_data = pd.concat([tracks_data, df_temp], axis=0)\n",
    "            \n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data_plus.csv', index=False)\n",
    "    \n",
    "    # Define search query\n",
    "    query = f'instrumentalness:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "            track_name = track['name']\n",
    "            track_artist = track['artists'][0]['name']\n",
    "            preview_url = track['preview_url']\n",
    "            df_temp = pd.DataFrame({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, index=[0])\n",
    "            #tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "            tracks_data = pd.concat([tracks_data, df_temp], axis=0)\n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data_plus.csv', index=False)\n",
    "    \n",
    "    # Define search query\n",
    "    query = f'speechiness:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "            track_name = track['name']\n",
    "            track_artist = track['artists'][0]['name']\n",
    "            preview_url = track['preview_url']\n",
    "            df_temp = pd.DataFrame({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, index=[0])\n",
    "            #tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "            tracks_data = pd.concat([tracks_data, df_temp], axis=0)\n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data_plus.csv', index=False)\n",
    "    \n",
    "    # Define search query\n",
    "    query = f'acousticness:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "            track_name = track['name']\n",
    "            track_artist = track['artists'][0]['name']\n",
    "            preview_url = track['preview_url']\n",
    "            df_temp = pd.DataFrame({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, index=[0])\n",
    "            #tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "            tracks_data = pd.concat([tracks_data, df_temp], axis=0)\n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data_plus.csv', index=False)\n",
    "    \n",
    "    # Define search query\n",
    "    query = f'energy:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "            track_name = track['name']\n",
    "            track_artist = track['artists'][0]['name']\n",
    "            preview_url = track['preview_url']\n",
    "            df_temp = pd.DataFrame({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, index=[0])\n",
    "            #tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "            tracks_data = pd.concat([tracks_data, df_temp], axis=0)\n",
    "            \n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data_plus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
