{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation and importing client ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spotipy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install torch: conda install pytorch torchvision torchaudio cpuonly -c pytorch\n",
    "\n",
    "Also need to install: matplotlib and pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "cid = '49789426e6c04428a2befbd3c2d79b02'\n",
    "secret = 'd18032252a0d4634aa8ca21356894e79'\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the existing csv files as dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "danceable_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/danceable_tracks-1.csv')\n",
    "non_danceable_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/non-danceable_tracks-1.csv')\n",
    "instrumental_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/instrumental_tracks-1.csv')\n",
    "non_instrumental_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/non-instrumental_tracks-1.csv')\n",
    "speechy_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/speechy_tracks-1.csv')\n",
    "non_speechy_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/non-speechy_tracks-1.csv')\n",
    "acoustic_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/acoustic_tracks-1.csv')\n",
    "non_acoustic_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/non-acoustic_tracks-1.csv')\n",
    "energetic_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/energetic_tracks-1.csv')\n",
    "non_energetic_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/non-energetic_tracks-1.csv')\n",
    "all_tracks_df = pd.read_csv('/Users/cheffbcookin/Desktop/EC523/Song_Feature_Pred/Sample_Data/all_tracks-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'Danceable Tracks': danceable_tracks_df,\n",
    "    'Non-danceable Tracks': non_danceable_tracks_df,\n",
    "    'Instrumental Tracks': instrumental_tracks_df,\n",
    "    'Non-instrumental Tracks': non_instrumental_tracks_df,\n",
    "    'Speechy Tracks': speechy_tracks_df,\n",
    "    'Non-speechy Tracks': non_speechy_tracks_df,\n",
    "    'Acoustic Tracks': acoustic_tracks_df,\n",
    "    'Non-acoustic Tracks': non_acoustic_tracks_df,\n",
    "    'Energetic Tracks': energetic_tracks_df,\n",
    "    'Non-energetic Tracks': non_energetic_tracks_df,\n",
    "    'All Tracks': all_tracks_df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in dataframes:\n",
    "    print(dataframe)\n",
    "    print(dataframes[dataframe].head(10))\n",
    "    print(dataframes[dataframe].columns)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize dictionary to hold list of tracks with specific features\n",
    "\n",
    "We will later save this dictionary and reuse it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing DataFrame from CSV file (if it exists)\n",
    "try:\n",
    "    tracks_data_base = pd.read_csv('tracks_data.csv')\n",
    "except FileNotFoundError:\n",
    "    tracks_data_base = pd.DataFrame(columns=['track_id', 'track_name', 'track_artist', 'preview_url'])\n",
    "    \n",
    "# Load existing DataFrame from CSV file (if it exists)\n",
    "try:\n",
    "    tracks_data = pd.read_csv('tracks_data_plus.csv')\n",
    "except FileNotFoundError:\n",
    "    tracks_data = pd.DataFrame(columns=['track_id', 'track_name', 'track_artist', 'preview_url'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting with grabbing data using just the feature and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define danceability range and step size\n",
    "start_danceability = 0.7\n",
    "end_danceability = 1.0\n",
    "step_size = 0.001\n",
    "\n",
    "# Iterate over danceability values and perform searches\n",
    "for danceability in reversed(range(int(start_danceability / step_size), int(end_danceability / step_size))):\n",
    "    # Define search query\n",
    "    query = f'danceability:{danceability*step_size:.2f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "            track_name = track['name']\n",
    "            track_artist = track['artists'][0]['name']\n",
    "            preview_url = track['preview_url']\n",
    "            tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "\n",
    "# Print number of tracks found and write to CSV file\n",
    "print(f'Found {len(tracks_data)} tracks')\n",
    "\n",
    "# Print tracks_data DataFrame\n",
    "print(tracks_data.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload the state of the large audio dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will save the data to a CSV file so that we can use it later\n",
    "\n",
    "#tracks_data_base.to_csv('tracks_data.csv', index=False)\n",
    "tracks_data_base = pd.read_csv('tracks_data.csv')\n",
    "print(f'Found {len(tracks_data_base)} tracks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from the CSV file\n",
    "tracks_data = pd.read_csv('tracks_data_plus.csv')\n",
    "print(f'Found {len(tracks_data)} tracks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature range and step size\n",
    "start = 0.0\n",
    "end = 1.0\n",
    "step_size = 0.005\n",
    "\n",
    "# Iterate over danceability values and perform searches\n",
    "for feature in reversed(range(int(start / step_size), int(end / step_size))):\n",
    "    # Define search query\n",
    "    print(f'working with feature interval: {feature*step_size:.3f}')\n",
    "    query = f'danceability:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id']:\n",
    "            if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "                track_name = track['name']\n",
    "                track_artist = track['artists'][0]['name']\n",
    "                preview_url = track['preview_url']\n",
    "                tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "\n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data.csv', index=False)\n",
    "    \n",
    "    # Define search query\n",
    "    query = f'instrumentalness:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id']:\n",
    "            track_id = track['id']\n",
    "            if track_id not in tracks_data['track_id'].values:\n",
    "                track_name = track['name']\n",
    "                track_artist = track['artists'][0]['name']\n",
    "                preview_url = track['preview_url']\n",
    "                tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "\n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data.csv', index=False)\n",
    "    \n",
    "    # Define search query\n",
    "    query = f'speechiness:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id']:\n",
    "            if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "                track_name = track['name']\n",
    "                track_artist = track['artists'][0]['name']\n",
    "                preview_url = track['preview_url']\n",
    "                tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "\n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data.csv', index=False)\n",
    "    \n",
    "    # Define search query\n",
    "    query = f'acousticness:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id']:\n",
    "            if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "                track_name = track['name']\n",
    "                track_artist = track['artists'][0]['name']\n",
    "                preview_url = track['preview_url']\n",
    "                tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "\n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data.csv', index=False)\n",
    "    \n",
    "    # Define search query\n",
    "    query = f'energy:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id']:\n",
    "            if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "                track_name = track['name']\n",
    "                track_artist = track['artists'][0]['name']\n",
    "                preview_url = track['preview_url']\n",
    "                tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "\n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THIS IS ONLY IF WE NEED EVEN MORE DATA\n",
    "\n",
    "We did indeed need even more metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature range and step size\n",
    "start = 0.0\n",
    "end = 1.0\n",
    "step_size = 0.001\n",
    "\n",
    "# Iterate over danceability values and perform searches\n",
    "for feature in reversed(range(int(start / step_size), int(end / step_size))):\n",
    "    # Define search query\n",
    "    print(f'working with feature interval: {feature*step_size:.3f}')\n",
    "    query = f'danceability:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "            track_name = track['name']\n",
    "            track_artist = track['artists'][0]['name']\n",
    "            preview_url = track['preview_url']\n",
    "            df_temp = pd.DataFrame({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, index=[0])\n",
    "            #tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "            tracks_data = pd.concat([tracks_data, df_temp], axis=0)\n",
    "            \n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data_plus.csv', index=False)\n",
    "    \n",
    "    # Define search query\n",
    "    query = f'instrumentalness:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "            track_name = track['name']\n",
    "            track_artist = track['artists'][0]['name']\n",
    "            preview_url = track['preview_url']\n",
    "            df_temp = pd.DataFrame({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, index=[0])\n",
    "            #tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "            tracks_data = pd.concat([tracks_data, df_temp], axis=0)\n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data_plus.csv', index=False)\n",
    "    \n",
    "    # Define search query\n",
    "    query = f'speechiness:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "            track_name = track['name']\n",
    "            track_artist = track['artists'][0]['name']\n",
    "            preview_url = track['preview_url']\n",
    "            df_temp = pd.DataFrame({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, index=[0])\n",
    "            #tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "            tracks_data = pd.concat([tracks_data, df_temp], axis=0)\n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data_plus.csv', index=False)\n",
    "    \n",
    "    # Define search query\n",
    "    query = f'acousticness:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "            track_name = track['name']\n",
    "            track_artist = track['artists'][0]['name']\n",
    "            preview_url = track['preview_url']\n",
    "            df_temp = pd.DataFrame({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, index=[0])\n",
    "            #tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "            tracks_data = pd.concat([tracks_data, df_temp], axis=0)\n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data_plus.csv', index=False)\n",
    "    \n",
    "    # Define search query\n",
    "    query = f'energy:{feature*step_size:.3f}'\n",
    "\n",
    "    # Search for tracks\n",
    "    results = sp.search(q=query, type='track', market='US', limit=50)\n",
    "\n",
    "    # Add new tracks to tracks_data DataFrame (if not already in DataFrame)\n",
    "    for track in results['tracks']['items']:\n",
    "        if track['id'] is not None and track['id'] not in tracks_data['track_id'].values:\n",
    "            track_name = track['name']\n",
    "            track_artist = track['artists'][0]['name']\n",
    "            preview_url = track['preview_url']\n",
    "            df_temp = pd.DataFrame({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, index=[0])\n",
    "            #tracks_data = tracks_data.append({'track_id': track_id, 'track_name': track_name, 'track_artist': track_artist, 'preview_url': preview_url}, ignore_index=True)\n",
    "            tracks_data = pd.concat([tracks_data, df_temp], axis=0)\n",
    "            \n",
    "    # Print number of tracks found and write to CSV file\n",
    "    print(f'Found {len(tracks_data)} tracks')\n",
    "    tracks_data.to_csv('tracks_data_plus.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label collection\n",
    "\n",
    "We've done the grunt work to collect all the tracks that would provide us with a wide range of data for our desired features. Now we go through and grab all the audio features for this set of tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Obtain an access token\n",
    "auth_url = 'https://accounts.spotify.com/api/token'\n",
    "\n",
    "auth_response = requests.post(\n",
    "    auth_url,\n",
    "    data={\n",
    "        'grant_type': 'client_credentials',\n",
    "        'client_id': cid,\n",
    "        'client_secret': secret\n",
    "    }\n",
    ")\n",
    "\n",
    "auth_response_data = auth_response.json()\n",
    "access_token = auth_response_data['access_token']\n",
    "\n",
    "print(access_token)\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {access_token}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_data_base = pd.read_csv('tracks_data.csv')\n",
    "print(f'Found {len(tracks_data_base)} tracks')\n",
    "\n",
    "tracks_data = pd.read_csv('tracks_data_plus.csv')\n",
    "print(f'Found {len(tracks_data)} tracks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a threshold for desired features\n",
    "danceability_threshold = 0.5\n",
    "non_danceability_threshold = 0.5\n",
    "\n",
    "instrumentalness_threshold = 0.5\n",
    "non_instrumentalness_threshold = 0.5\n",
    "\n",
    "speechiness_threshold = 0.5\n",
    "non_speechiness_threshold = 0.5\n",
    "\n",
    "acousticness_threshold = 0.5\n",
    "non_acousticness_threshold = 0.5\n",
    "\n",
    "energy_threshold = 0.5\n",
    "non_energy_threshold = 0.5\n",
    "\n",
    "total_danceable = 0\n",
    "total_non_danceable = 0\n",
    "\n",
    "total_instrumental = 0\n",
    "total_non_instrumental = 0\n",
    "\n",
    "total_speechy = 0\n",
    "total_non_speechy = 0\n",
    "\n",
    "total_acoustic = 0\n",
    "total_non_acoustic = 0\n",
    "\n",
    "total_energetic = 0\n",
    "total_non_energetic = 0\n",
    "\n",
    "total = 0\n",
    "\n",
    "\n",
    "for index, track in tracks_data.iterrows():\n",
    "    # k += 1\n",
    "    track_id = track['track_id']\n",
    "    track_name = track['track_name']\n",
    "    track_artist = track['track_artist']\n",
    "    preview_url = track['preview_url']\n",
    "    \n",
    "    if preview_url and track_id not in all_tracks_df['track_id'].values:\n",
    "        # Fetch track's audio features\n",
    "        audio_features_url = f'https://api.spotify.com/v1/audio-features/{track_id}'\n",
    "        audio_features_response = requests.get(audio_features_url, headers=headers)\n",
    "        audio_features_data = audio_features_response.json()\n",
    "        \n",
    "        # Check if all audio features are present\n",
    "        required_features = ['danceability', 'instrumentalness', 'speechiness', 'acousticness', 'energy', 'valence', 'tempo', 'loudness', 'liveness', 'key', 'mode', 'time_signature']\n",
    "        if not all(feature in audio_features_data for feature in required_features):\n",
    "            # Remove the current row if any feature is missing\n",
    "            print(f'removing track {index+1} of {len(tracks_data)} from large numeric_based dataset')\n",
    "            tracks_data = tracks_data.drop(index)\n",
    "            \n",
    "            # check the necessary labels and remove tracks if the bare minimum is not met:\n",
    "            bare_minimum_required_labels = ['instrumentalness', 'speechiness', 'acousticness', 'energy']\n",
    "            if not all(feature in audio_features_data for feature in bare_minimum_required_labels):\n",
    "                \n",
    "                track_id_to_remove = track_id\n",
    "\n",
    "                # Find the index of the row with the track_id_to_remove value\n",
    "                if track_id_to_remove in tracks_data_base['track_id'].values:\n",
    "                    index_to_remove = tracks_data_base[tracks_data_base['track_id'] == track_id_to_remove].index\n",
    "                    # Remove rows with track ids in the list\n",
    "                    # List of track ids to remove\n",
    "                    if index_to_remove.empty:\n",
    "                        print(f'Track {track_id_to_remove} not found in tracks_data_base.')\n",
    "                    else:\n",
    "                        print(f'removing track from smaller dataset of length: {len(tracks_data_base)}')\n",
    "                        tracks_data_base = tracks_data_base.drop(index_to_remove)\n",
    "                        # Reindex the dataframe to start from 0\n",
    "                        tracks_data_base = tracks_data_base.reset_index(drop=True)\n",
    "            \n",
    "            # seeing how danceability is a new feature, we will continue with our labels without it for audio based RNNs\n",
    "            else:\n",
    "                print(f'working on track {index+1} of {len(tracks_data)} for smaller dataset')\n",
    "                # Check if the track is already in the DataFrame\n",
    "                if preview_url and track_id not in instrumental_tracks_df['track_id'].values:\n",
    "                \n",
    "                    # # Fetch track's audio features\n",
    "                    # audio_features_url = f'https://api.spotify.com/v1/audio-features/{track_id}'\n",
    "                    # audio_features_response = requests.get(audio_features_url, headers=headers)\n",
    "                    # audio_features_data = audio_features_response.json()\n",
    "\n",
    "                    # Check if the track's instrumentalness is greater than the threshold\n",
    "                    if audio_features_data['instrumentalness'] > instrumentalness_threshold:\n",
    "                        print(f'\\t{track_name} - {track_artist} (Instrumentalness: {audio_features_data[\"instrumentalness\"]})')\n",
    "                        # Append the new track to the DataFrame\n",
    "                        track_df = pd.DataFrame({\n",
    "                            'track_id': [track_id],\n",
    "                            'track_name': [track_name],\n",
    "                            'track_artist': [track_artist],\n",
    "                            'instrumentalness': [audio_features_data['instrumentalness']],\n",
    "                            'preview_url' : [preview_url]\n",
    "                        })\n",
    "                        \n",
    "                        # Concatenate the new DataFrame with the existing DataFrame\n",
    "                        instrumental_tracks_df = pd.concat([instrumental_tracks_df, track_df], ignore_index=True)\n",
    "                        \n",
    "                        total_instrumental = total_instrumental + 1\n",
    "                        \n",
    "                # Check if the track is already in the DataFrame\n",
    "                if preview_url and track_id not in non_instrumental_tracks_df['track_id'].values:\n",
    "                \n",
    "                    # # Fetch track's audio features\n",
    "                    # audio_features_url = f'https://api.spotify.com/v1/audio-features/{track_id}'\n",
    "                    # audio_features_response = requests.get(audio_features_url, headers=headers)\n",
    "                    # audio_features_data = audio_features_response.json()\n",
    "\n",
    "                    # Check if the track's instrumentalness is less than the threshold\n",
    "                    if audio_features_data['instrumentalness'] < non_instrumentalness_threshold:\n",
    "                        print(f'\\t{track_name} - {track_artist} (Instrumentalness: {audio_features_data[\"instrumentalness\"]})')\n",
    "                        # Append the new track to the DataFrame\n",
    "                        track_df = pd.DataFrame({\n",
    "                            'track_id': [track_id],\n",
    "                            'track_name': [track_name],\n",
    "                            'track_artist': [track_artist],\n",
    "                            'instrumentalness': [audio_features_data['instrumentalness']],\n",
    "                            'preview_url' : [preview_url]\n",
    "                        })\n",
    "                        \n",
    "                        # Concatenate the new DataFrame with the existing DataFrame\n",
    "                        non_instrumental_tracks_df = pd.concat([instrumental_tracks_df, track_df], ignore_index=True)\n",
    "                        \n",
    "                        total_non_instrumental = total_non_instrumental + 1\n",
    "                        \n",
    "                # Check if the track is already in the DataFrame\n",
    "                if preview_url and track_id not in speechy_tracks_df['track_id'].values:\n",
    "                \n",
    "                    # # Fetch track's audio features\n",
    "                    # audio_features_url = f'https://api.spotify.com/v1/audio-features/{track_id}'\n",
    "                    # audio_features_response = requests.get(audio_features_url, headers=headers)\n",
    "                    # audio_features_data = audio_features_response.json()\n",
    "\n",
    "                    # Check if the track's speechiness is greater than the threshold\n",
    "                    if audio_features_data['speechiness'] > speechiness_threshold:\n",
    "                        print(f'\\t{track_name} - {track_artist} (Speechiness: {audio_features_data[\"speechiness\"]})')\n",
    "                        # Append the new track to the DataFrame\n",
    "                        track_df = pd.DataFrame({\n",
    "                            'track_id': [track_id],\n",
    "                            'track_name': [track_name],\n",
    "                            'track_artist': [track_artist],\n",
    "                            'speechiness': [audio_features_data['speechiness']],\n",
    "                            'preview_url' : [preview_url]\n",
    "                        })\n",
    "                        \n",
    "                        # Concatenate the new DataFrame with the existing DataFrame\n",
    "                        speechy_tracks_df = pd.concat([speechy_tracks_df, track_df], ignore_index=True)\n",
    "                        \n",
    "                        total_speechy = total_speechy + 1\n",
    "                        \n",
    "                if preview_url and track_id not in non_speechy_tracks_df['track_id'].values:\n",
    "                    \n",
    "                    # # Fetch track's audio features\n",
    "                    # audio_features_url = f'https://api.spotify.com/v1/audio-features/{track_id}'\n",
    "                    # audio_features_response = requests.get(audio_features_url, headers=headers)\n",
    "                    # audio_features_data = audio_features_response.json()\n",
    "                    \n",
    "                    # Check if the track's speechiness is less than the threshold\n",
    "                    if audio_features_data['speechiness'] < non_speechiness_threshold:\n",
    "                        print(f'\\t{track_name} - {track_artist} (Speechiness: {audio_features_data[\"speechiness\"]})')\n",
    "                        # Append the new track to the DataFrame\n",
    "                        track_df = pd.DataFrame({\n",
    "                            'track_id': [track_id],\n",
    "                            'track_name': [track_name],\n",
    "                            'track_artist': [track_artist],\n",
    "                            'speechiness': [audio_features_data['speechiness']],\n",
    "                            'preview_url' : [preview_url]\n",
    "                        })\n",
    "                        \n",
    "                        # Concatenate the new DataFrame with the existing DataFrame\n",
    "                        non_speechy_tracks_df = pd.concat([non_speechy_tracks_df, track_df], ignore_index=True)\n",
    "                        \n",
    "                        total_non_speechy = total_non_speechy + 1\n",
    "                        \n",
    "                if preview_url and track_id not in acoustic_tracks_df['track_id'].values:\n",
    "                    \n",
    "                    # # Fetch track's audio features\n",
    "                    # audio_features_url = f'https://api.spotify.com/v1/audio-features/{track_id}'\n",
    "                    # audio_features_response = requests.get(audio_features_url, headers=headers)\n",
    "                    # audio_features_data = audio_features_response.json()\n",
    "                    \n",
    "                    # Check if the track's acousticness is greater than the threshold\n",
    "                    if audio_features_data['acousticness'] > acousticness_threshold:\n",
    "                        print(f'\\t{track_name} - {track_artist} (Acousticness: {audio_features_data[\"acousticness\"]})')\n",
    "                        # Append the new track to the DataFrame\n",
    "                        track_df = pd.DataFrame({\n",
    "                            'track_id': [track_id],\n",
    "                            'track_name': [track_name],\n",
    "                            'track_artist': [track_artist],\n",
    "                            'acousticness': [audio_features_data['acousticness']],\n",
    "                            'preview_url' : [preview_url]\n",
    "                        })\n",
    "                        \n",
    "                        # Concatenate the new DataFrame with the existing DataFrame\n",
    "                        acoustic_tracks_df = pd.concat([acoustic_tracks_df, track_df], ignore_index=True)\n",
    "                        \n",
    "                        total_acoustic = total_acoustic + 1\n",
    "                        \n",
    "                if preview_url and track_id not in non_acoustic_tracks_df['track_id'].values:\n",
    "                    \n",
    "                    # # Fetch track's audio features\n",
    "                    # audio_features_url = f'https://api.spotify.com/v1/audio-features/{track_id}'\n",
    "                    # audio_features_response = requests.get(audio_features_url, headers=headers)\n",
    "                    # audio_features_data = audio_features_response.json()\n",
    "                    \n",
    "                    # Check if the track's acousticness is less than the threshold\n",
    "                    if audio_features_data['acousticness'] < non_acousticness_threshold:\n",
    "                        print(f'\\t{track_name} - {track_artist} (Acousticness: {audio_features_data[\"acousticness\"]})')\n",
    "                        # Append the new track to the DataFrame\n",
    "                        track_df = pd.DataFrame({\n",
    "                            'track_id': [track_id],\n",
    "                            'track_name': [track_name],\n",
    "                            'track_artist': [track_artist],\n",
    "                            'acousticness': [audio_features_data['acousticness']],\n",
    "                            'preview_url' : [preview_url]\n",
    "                        })\n",
    "                        \n",
    "                        # Concatenate the new DataFrame with the existing DataFrame\n",
    "                        non_acoustic_tracks_df = pd.concat([non_acoustic_tracks_df, track_df], ignore_index=True)\n",
    "                        \n",
    "                        total_non_acoustic = total_non_acoustic + 1\n",
    "                        \n",
    "                if preview_url and track_id not in energetic_tracks_df['track_id'].values:\n",
    "                    \n",
    "                    # # Fetch track's audio features\n",
    "                    # audio_features_url = f'https://api.spotify.com/v1/audio-features/{track_id}'\n",
    "                    # audio_features_response = requests.get(audio_features_url, headers=headers)\n",
    "                    # audio_features_data = audio_features_response.json()\n",
    "                    \n",
    "                    # Check if the track's energy is greater than the threshold\n",
    "                    if audio_features_data['energy'] > energy_threshold:\n",
    "                        print(f'\\t{track_name} - {track_artist} (Energy: {audio_features_data[\"energy\"]})')\n",
    "                        # Append the new track to the DataFrame\n",
    "                        track_df = pd.DataFrame({\n",
    "                            'track_id': [track_id],\n",
    "                            'track_name': [track_name],\n",
    "                            'track_artist': [track_artist],\n",
    "                            'energy': [audio_features_data['energy']],\n",
    "                            'preview_url' : [preview_url]\n",
    "                        })\n",
    "                        \n",
    "                        # Concatenate the new DataFrame with the existing DataFrame\n",
    "                        energetic_tracks_df = pd.concat([energetic_tracks_df, track_df], ignore_index=True)\n",
    "                        \n",
    "                        total_energetic = total_energetic + 1\n",
    "                        \n",
    "                        \n",
    "                if preview_url and track_id not in non_energetic_tracks_df['track_id'].values:\n",
    "                    \n",
    "                    # # Fetch track's audio features\n",
    "                    # audio_features_url = f'https://api.spotify.com/v1/audio-features/{track_id}'\n",
    "                    # audio_features_response = requests.get(audio_features_url, headers=headers)\n",
    "                    # audio_features_data = audio_features_response.json()\n",
    "                    \n",
    "                    # Check if the track's energy is less than the threshold\n",
    "                    if audio_features_data['energy'] < non_energy_threshold:\n",
    "                        print(f'\\t{track_name} - {track_artist} (Energy: {audio_features_data[\"energy\"]})')\n",
    "                        # Append the new track to the DataFrame\n",
    "                        track_df = pd.DataFrame({\n",
    "                            'track_id': [track_id],\n",
    "                            'track_name': [track_name],\n",
    "                            'track_artist': [track_artist],\n",
    "                            'energy': [audio_features_data['energy']],\n",
    "                            'preview_url' : [preview_url]\n",
    "                        })\n",
    "                        \n",
    "                        # Concatenate the new DataFrame with the existing DataFrame\n",
    "                        non_energetic_tracks_df = pd.concat([non_energetic_tracks_df, track_df], ignore_index=True)\n",
    "                        \n",
    "                        total_non_energetic = total_non_energetic + 1\n",
    "                        \n",
    "        else:\n",
    "            print(f'Processing track {index+1} of {len(tracks_data)}')\n",
    "            \n",
    "            # add to all \n",
    "            track_df = pd.DataFrame({\n",
    "                'track_id': [track_id],\n",
    "                'track_name': [track_name],\n",
    "                'track_artist': [track_artist],\n",
    "                'danceability': [audio_features_data['danceability']],\n",
    "                'instrumentalness': [audio_features_data['instrumentalness']],\n",
    "                'speechiness': [audio_features_data['speechiness']],\n",
    "                'acousticness': [audio_features_data['acousticness']],\n",
    "                'energy': [audio_features_data['energy']],\n",
    "                'valence': [audio_features_data['valence']],\n",
    "                'tempo': [audio_features_data['tempo']],\n",
    "                'loudness': [audio_features_data['loudness']],\n",
    "                'liveness': [audio_features_data['liveness']],\n",
    "                'key': [audio_features_data['key']],\n",
    "                'mode': [audio_features_data['mode']],\n",
    "                'time_signature': [audio_features_data['time_signature']],\n",
    "                'preview_url' : [preview_url]\n",
    "            })\n",
    "            all_tracks_df = pd.concat([all_tracks_df, track_df], ignore_index=True)\n",
    "            total = total + 1\n",
    "\n",
    "    \n",
    "            # Check if the track is already in the DataFrame\n",
    "            if preview_url and track_id not in danceable_tracks_df['track_id'].values:\n",
    "                # # Fetch track's audio features\n",
    "                # audio_features_url = f'https://api.spotify.com/v1/audio-features/{track_id}'\n",
    "                # audio_features_response = requests.get(audio_features_url, headers=headers)\n",
    "                # audio_features_data = audio_features_response.json()\n",
    "\n",
    "                # Check if the track's danceability is greater than the threshold\n",
    "                if audio_features_data['danceability'] > danceability_threshold:\n",
    "                    print(f'\\t{track_name} - {track_artist} (Danceability: {audio_features_data[\"danceability\"]})')\n",
    "                    # Append the new track to the DataFrame\n",
    "                    track_df = pd.DataFrame({\n",
    "                        'track_id': [track_id],\n",
    "                        'track_name': [track_name],\n",
    "                        'track_artist': [track_artist],\n",
    "                        'danceability': [audio_features_data['danceability']],\n",
    "                        'preview_url' : [preview_url]\n",
    "                    })\n",
    "                    \n",
    "                    # Concatenate the new DataFrame with the existing DataFrame\n",
    "                    danceable_tracks_df = pd.concat([danceable_tracks_df, track_df], ignore_index=True)\n",
    "                    \n",
    "                    total_danceable = total_danceable + 1\n",
    "                    \n",
    "            # Check if the track is already in the DataFrame\n",
    "            if preview_url and track_id not in non_danceable_tracks_df['track_id'].values:\n",
    "            \n",
    "                # # Fetch track's audio features\n",
    "                # audio_features_url = f'https://api.spotify.com/v1/audio-features/{track_id}'\n",
    "                # audio_features_response = requests.get(audio_features_url, headers=headers)\n",
    "                # audio_features_data = audio_features_response.json()\n",
    "\n",
    "                # Check if the track's danceability is less than the threshold\n",
    "                if audio_features_data['danceability'] < non_danceability_threshold:\n",
    "                    print(f'\\t{track_name} - {track_artist} (Danceability: {audio_features_data[\"danceability\"]})')\n",
    "                    # Append the new track to the DataFrame\n",
    "                    track_df = pd.DataFrame({\n",
    "                        'track_id': [track_id],\n",
    "                        'track_name': [track_name],\n",
    "                        'track_artist': [track_artist],\n",
    "                        'danceability': [audio_features_data['danceability']],\n",
    "                        'preview_url' : [preview_url]\n",
    "                    })\n",
    "                    \n",
    "                    # Concatenate the new DataFrame with the existing DataFrame\n",
    "                    non_danceable_tracks_df = pd.concat([danceable_tracks_df, track_df], ignore_index=True)\n",
    "                    \n",
    "                    total_non_danceable = total_non_danceable + 1\n",
    "                    \n",
    "            \n",
    "                \n",
    "dataframes = {\n",
    "    'Danceable Tracks': danceable_tracks_df,\n",
    "    'Non-danceable Tracks': non_danceable_tracks_df,\n",
    "    'Instrumental Tracks': instrumental_tracks_df,\n",
    "    'Non-instrumental Tracks': non_instrumental_tracks_df,\n",
    "    'Speechy Tracks': speechy_tracks_df,\n",
    "    'Non-speechy Tracks': non_speechy_tracks_df,\n",
    "    'Acoustic Tracks': acoustic_tracks_df,\n",
    "    'Non-acoustic Tracks': non_acoustic_tracks_df,\n",
    "    'Energetic Tracks': energetic_tracks_df,\n",
    "    'Non-energetic Tracks': non_energetic_tracks_df,\n",
    "    'All Tracks': all_tracks_df\n",
    "}\n",
    "           \n",
    "print(f'Total tracks: {total}')\n",
    "print(f'Total danceable tracks: {total_danceable}')\n",
    "print(f'Total non-danceable tracks: {total_non_danceable}')\n",
    "print(f'Total speechy tracks: {total_speechy}')\n",
    "print(f'Total non-speechy tracks: {total_non_speechy}')\n",
    "print(f'Total acoustic tracks: {total_acoustic}')\n",
    "print(f'Total non-acoustic tracks: {total_non_acoustic}')\n",
    "print(f'Total energetic tracks: {total_energetic}')\n",
    "print(f'Total non-energetic tracks: {total_non_energetic}')\n",
    "print(f'Total instrumental tracks: {total_instrumental}')\n",
    "print(f'Total non-instrumental tracks: {total_non_instrumental}')\n",
    "\n",
    "# # Display the DataFrame with danceable tracks\n",
    "# print(danceable_tracks_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above things all seem to have resulted in failure because of the lack of features for the collected tracks. Starting from scratch."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframes_to_csv(dataframes):\n",
    "    for df_name, df in dataframes.items():\n",
    "        filename = df_name.replace(\" \", \"_\").lower() + \"-2.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Saved {df_name} to {filename}\")\n",
    "\n",
    "save_dataframes_to_csv(dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(danceable_tracks_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New method of collecting audio based on purely gengres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.65.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tracks(query, limit, offset):\n",
    "    results = sp.search(q=query, type='track', limit=limit, offset=offset)\n",
    "    return results['tracks']['items']\n",
    "\n",
    "def get_track_features(track_ids):\n",
    "    features = sp.audio_features(track_ids)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY = 5  # seconds\n",
    "\n",
    "def search_tracks(query, limit, offset):\n",
    "    retries = 0\n",
    "    while retries < MAX_RETRIES:\n",
    "        try:\n",
    "            # response = requests.get(\n",
    "            #     'https://api.spotify.com/v1/search',\n",
    "            #     params={\n",
    "            #         'q': query,\n",
    "            #         'type': 'track',\n",
    "            #         'limit': limit,\n",
    "            #         'offset': offset\n",
    "            #     }\n",
    "            # )\n",
    "            response = sp.search(q=query, type='track', limit=limit, offset=offset)\n",
    "            # response.raise_for_status()\n",
    "            #data = response.json()\n",
    "            return response['tracks']['items']\n",
    "        except (requests.exceptions.RequestException, ValueError):\n",
    "            # Catch any HTTP errors or JSON parsing errors\n",
    "            retries += 1\n",
    "            time.sleep(RETRY_DELAY)\n",
    "    # If we've exceeded the maximum number of retries, raise an exception\n",
    "    raise Exception(f\"Failed to fetch search results after {MAX_RETRIES} retries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "required_features = ['danceability', 'instrumentalness', 'speechiness', 'acousticness', 'energy', 'valence', 'tempo', 'loudness', 'liveness', 'key', 'mode', 'time_signature']\n",
    "\n",
    "def compile_tracks(query, total_tracks, limit=50):\n",
    "    tracks_df = pd.DataFrame()\n",
    "    keywords = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "    # Initialize the progress bar\n",
    "    with tqdm(total=total_tracks) as pbar:\n",
    "        while tracks_df.shape[0] < total_tracks:\n",
    "            keyword = random.choice(keywords)\n",
    "            remaining_tracks = total_tracks - tracks_df.shape[0]\n",
    "            current_limit = min(limit, remaining_tracks)\n",
    "            offset = 0\n",
    "\n",
    "            while offset < 800:\n",
    "                search_result = search_tracks(f\"{query} {keyword}\", current_limit, offset)\n",
    "                track_ids = [track['id'] for track in search_result]\n",
    "                track_previews = [track['preview_url'] for track in search_result]\n",
    "                track_names = [track['name'] for track in search_result]\n",
    "\n",
    "                if not track_ids:\n",
    "                    break\n",
    "\n",
    "                features = get_track_features(track_ids)\n",
    "\n",
    "                temp_df = pd.DataFrame(features)\n",
    "                temp_df['preview_url'] = track_previews\n",
    "                temp_df['track_name'] = track_names\n",
    "\n",
    "                # Filter out tracks that do not have all the required features\n",
    "                temp_df = temp_df.dropna(subset=required_features)\n",
    "\n",
    "                # Filter out the duplicate tracks if the 'id' column exists in both DataFrames\n",
    "                if 'id' in tracks_df.columns and 'id' in temp_df.columns:\n",
    "                    temp_df = temp_df.loc[~temp_df['id'].isin(tracks_df['id'])]\n",
    "\n",
    "                tracks_df = pd.concat([tracks_df, temp_df], ignore_index=True)\n",
    "\n",
    "                # Update the progress bar with the number of new tracks added\n",
    "                pbar.update(temp_df.shape[0])\n",
    "\n",
    "                offset += current_limit\n",
    "                time.sleep(random.uniform(1, 3))\n",
    "\n",
    "            if tracks_df.shape[0] >= total_tracks:\n",
    "                break\n",
    "\n",
    "    return tracks_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 300/2500 [00:21<02:22, 15.43it/s]"
     ]
    }
   ],
   "source": [
    "genres = ['pop', 'rock', 'hip-hop', 'classical', 'jazz', 'country', 'electronic', 'reggae']\n",
    "total_tracks_per_genre = 20000 // len(genres)\n",
    "tracks_df_full = pd.DataFrame()\n",
    "\n",
    "for genre in genres:\n",
    "    query = f\"genre:{genre}\"\n",
    "    genre_tracks_df = compile_tracks(query, total_tracks_per_genre)\n",
    "    # tracks_df = tracks_df.append(genre_tracks_df, ignore_index=True)\n",
    "    tracks_df_full = pd.concat([tracks_df_full, genre_tracks_df], ignore_index=True)\n",
    "    print(len(tracks_df_full))\n",
    "\n",
    "tracks_df_full.to_csv('tracks_features.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(track_df_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
